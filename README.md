# RNA-Seq_genome_assembly_and_annotation
This repository is a usable, publicly available genome annotation and assembly tutorial.
This tutorial assumes the user is using a Linux system (or Ubuntu 17.0.1 or higher).

<div id="toc_container">
<p class="toc_title">Contents</p>
<ul class="toc_list">
<li><a href="#First_Point_Header">1 Overview and programs install</>
<li><a href="#Second_Point_Header">2 Accessing the data using sra-toolkit</a></li>
<li><a href="#Third_Point_Header">3 Quality control using sickle</a></li>
<li><a href="#Fourth_Point_Header">4 Aligning reads to a genome using hisat2</a></li>
<li><a href="#Fifth_Point_Header">5 Generating total read counts from alignment using htseq-count</a></li>
<li><a href="#Sixth_Point_Header">6 Pairwise differential expression with counts in R with DESeq2</a></li>
  <li><a href="#Citation"> Citations</a><li>
</ul>
</div>

<h2 id="First_Point_Header">Overview and programs install</h2>
Marine RNA-Seq
In this tutorial we will be analyzing 2 liver samples from the large yellow croaker (Larimichthys crocea) from the NCBI BioProject (https://www.ncbi.nlm.nih.gov/bioproject/280841 )
Experimental Design:
Liver mRNA profiles large yellow croaker (Larimichthys crocea) species are sampled during various conditions namely, control group (LB2A), thermal stress group (LC2A), cold stress group (LA2A) and 21-day fasting group (LF1A) were generated by RNA-seq, using Illumina HiSeq 2000
We will use the control group (LB2A) and the thermal stress group (LC2A)j

The workflow may be cloned using the terminal command:
  $git clone https://github.com/wolf-adam-eily/RNA-Seq_genome_assembly_and_annotation.git
  $cd RNA-Seq_genome_assembly_and_annotation
  $ls  

After cloning the repository but before beginning the tutorial, it is recommended the command (in the cloned folder):
  sh -e programs_installation
  sh -e r_3.4.3_install
(if an absolute directory error occurs, edit the script to change "~/R-3.4.3" to "/home/(insert_user_name)/R-3.4.3")
  sudo Rscript r_packages_install
be run to install <i><b>all</b></i> of the needed software and tools for this tutorial,.

<h2 id="Second_Point_Header">Accessing the data using sra-toolkit </h2>

https://www.ncbi.nlm.nih.gov/bioproject/280841

LF1A : SRR1964648, SRR1964649
LF2A : SRR1964647, SRR1964646
LB2A : SRR1964642, SRR1964643
LC2A : SRR1964644, SRR1964645

 fastq-dump SRR1964642
 fastq-dump SRR1964643

Repeat fastq-dump for SRR1964644 and SRR1964645 samples, or alternatively run either of the following commands (change directory to the RNA-Seq_genome_assembly_and_annotation folder first):
  sh -e fastqdump_server
or
  sh -e fastqdump_and_trim_personal_computer
The first command will simply download the four fastq files to your server. If proceeding through this tutorial on a personal computer or laptop without access to a server, run the second command. This command will combine the fastq-dump with the next step, quality control, downloading a fastq file, trimming that file, and the removing the untrimmed file. This is recommended if disk space is an issue (the four files combined consume about 75GB of disk space).
 Once download is completed, the files were renamed according to the samples for easy identification. If the first command was run, you should see the following files in your folder: 
|-- LB2A_SRR1964642.fastq
|-- LB2A_SRR1964643.fastq
|-- LC2A_SRR1964644.fastq
|-- LC2A_SRR1964645.fastq

The above folder is located at /common/RNASeq_Workshop/Marine/raw_data in BBC
<h2 id="Third_Point_Header">Quality control using sickle</h2>

 Sickle performs quality control on illumina paired-end and single-end short read data. The following command can be applied to each of the four read fastq files:
 
 sickle se -f LB2A_SRR1964642.fastq -t sanger -o trimmed_LB2A_SRR1964642.fastq -q 30 -l 50

 The options we use;


Options: 
se    Single end reads
-f    input file name
-o    output file name
-q    scan the read with the sliding window, cutting when the average quality per base drops below 30 
-l    Removes any reads shorter than 50bp

This can be repeated for all four files (if the fastq_dump_server option was exercised, if the fastq_dump_personal_computer option was used then this step has already been completed) by running the shell script:
  sh -e fastq_trimming_server
 
Following the sickle run, the resulting file structure will look as follows:

|-- trimmed_LB2A_SRR1964642.fastq
|-- trimmed_LB2A_SRR1964643.fastq
|-- trimmed_LC2A_SRR1964644.fastq
|-- trimmed_LC2A_SRR1964645.fastq

Examine the .out file generated during the run.  It will provide a summary of the quality control process.

Input Reads: 26424138 Surviving: 21799606 (82.50%) Dropped: 4624532 (17.50%)

<h2 id="Fourth_Point_Header">Aligning reads to a genome using hisat2</h2>
Building an Index
HISAT2 is a fast and sensitive aligner for mapping next generation sequencing reads against a reference genome.

In order to map the reads to a reference genome, first you need to download the reference genome, and make a index file. We will be downloading the reference genome (https://www.ncbi.nlm.nih.gov/genome/12197) from the ncbi database, using the wget command.

wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/972/845/GCF_000972845.1_L_crocea_1.0/GCF_000972845.1_L_crocea_1.0_genomic.fna.gz

IF you feel to be prudent, you can install the genomic, transcriptomic, and proteomic fastas (yes, all will be used in this tutorial, it is advised you download them now) with the command:
 
 sh -e genomic_and_protein_downloads

We will use hisat2-build package in the software to make a HISAT index file for the genome. It will create a set of files with the suffix .ht2, these files together build the index, this is all you need to align the reads to the reference genome (this command is included in the genome_indexing_and_alignment* files, so it is not necessary to run now).

hisat2-build -p 4 GCF_000972845.1_L_crocea_1.0_genomic.fna L_crocea

Usage: hisat2-build [options] <reference_in> <bt2_index_base>
reference_in                comma-separated list of files with ref sequences
hisat2_index_base           write ht2 data to files with this dir/basename

Options:
    -p                      number of threads

After running the script, the following files will be generated as part of the index.  To refer to the index for  mapping the reads in the next step, you will use the file prefix, which in this case is: L_crocea

|-- GCF_000972845.1_L_crocea_1.0_genomic.fna
|-- hisat2_index.sh
|-- L_crocea.1.ht2
|-- L_crocea.2.ht2
|-- L_crocea.3.ht2
|-- L_crocea.4.ht2
|-- L_crocea.5.ht2
|-- L_crocea.6.ht2
|-- L_crocea.7.ht2
|-- L_crocea.8.ht2

Aligning the reads using HISAT2
Once we have created the index, the next step is to align the reads using the index we created. To do this we will be using hisat2 program. The program will give the output in SAM format, which can be used my various programs.

hisat2 -p 4 --dta -x ../index/L_crocea -q ../quality_control/trim_LB2A_SRR1964642.fastq -S trim_LB2A_SRR1964642.sam

Usage: hisat2 [options]* -x <ht2-idx>  [-S <sam>]
-x <ht2-idx>        path to the Index-filename-prefix (minus trailing .X.ht2) 

[]
Options:
-q                  query input files are FASTQ .fq/.fastq (default)
-p                  number threads
--dta               reports alignments tailored for transcript assemblers

The above must be repeated for all the files. You may run:

  sh -e genome_indexing_and_alignment_server
or
  sh -e genome_indexing_and_alignment_personal_computer

to process all four files appropriate for your setup.

Once the mapping have been completed, the file structure is as follows:

|-- mapping.sh
|-- trim_LB2A_SRR1964642.sam
|-- trim_LB2A_SRR1964643.sam
|-- trim_LC2A_SRR1964644.sam
|-- trim_LC2A_SRR1964645.sam

When HISAT2 completes its run, it will summarize each of it’s alignments, and it is written to the standard error file, which can be find in the same folder once the run is completed.

21799606 reads; of these:
  21799606 (100.00%) were unpaired; of these:
    1678851 (7.70%) aligned 0 times
    15828295 (72.61%) aligned exactly 1 time
    4292460 (19.69%) aligned >1 times
92.30% overall alignment rate

The sam file then need to be converted in to bam format;

samtools view -@ 4 -uhS trim_LB2A_SRR1964642.sam | samtools sort -@ 4 - sort_trim_LB2A_SRR1964642

 Usage: samtools [command] [options] in.sam
Command:
view     prints all alignments in the specified input alignment file (in SAM, BAM, or CRAM format) to standard output in SAM format 

Options:
-h      Include the header in the output
-S      Indicate the input was in SAM format
-u      Output uncompressed BAM. This option saves time spent on compression/decompression and is thus preferred when the output is piped to another samtools command
-@      Number of processors

Usage: samtools [command] [-o out.bam]
Command:
sort    Sort alignments by leftmost coordinates

-o      Write the final sorted output to FILE, rather than to standard output.

All samples may be run by executing the following command:

  sh -e sam_to_bam_server
or
  sh -e sam_to_bam_personal_computer

appropriate for your set-up.

Once the conversion is done you will have the following files in the directory.

|-- sort_trim_LB2A_SRR1964642.bam
|-- sort_trim_LB2A_SRR1964643.bam
|-- sort_trim_LC2A_SRR1964644.bam
|-- sort_trim_LC2A_SRR1964645.bam

<h2 id="Fifth_Point_Header">Generating total read counts from alignent using htseq-count</h2>
Now we will be using the htseq-count program to count the reads which is mapping to the genome.

htseq-count -s no -r pos -t gene -i Dbxref -f bam ../mapping/sort_trim_LB2A_SRR1964642.bam GCF_000972845.1_L_crocea_1.0_genomic.gff > LB2A_SRR1964642.counts
Usage: htseq-count [options] alignment_file gff_file

This script takes an alignment file in SAM/BAM format and a feature file in
GFF format and calculates for each feature the number of reads mapping to it.
See http://www-huber.embl.de/users/anders/HTSeq/doc/count.html for details.

Options:
  -f SAMTYPE, --format=SAMTYPE
                        type of  data, either 'sam' or 'bam'
                        (default: sam)
  -r ORDER, --order=ORDER
                        'pos' or 'name'. Sorting order of 
                        (default: name). Paired-end sequencing data must be
                        sorted either by position or by read name, and the
                        sorting order must be specified. Ignored for single-
                        end data.
  -s STRANDED, --stranded=STRANDED
                        whether the data is from a strand-specific assay.
                        Specify 'yes', 'no', or 'reverse' (default: yes).
                        'reverse' means 'yes' with reversed strand
                        interpretation
  -t FEATURETYPE, --type=FEATURETYPE
                        feature type (3rd column in GFF file) to be used, all
                        features of other type are ignored (default, suitable
                        for Ensembl GTF files: exon)
  -i IDATTR, --idattr=IDATTR
                        GFF attribute to be used as feature ID (default,
                        suitable for Ensembl GTF files: gene_id)

 
The above command should be repeated for all other BAM files as well. You can process all the BAM files with the command:

  sh -e htseq_count_server
or
  sh -e htseq_count_personal_computer

appropriate for your set-up.

Once all the bam files have been counted, we will be having the following files in the directory.

|-- sort_trim_LB2A_SRR1964642.counts
|-- sort_trim_LB2A_SRR1964643.counts
|-- sort_trim_LC2A_SRR1964644.counts
|-- sort_trim_LC2A_SRR1964645.counts

<h2 id="Sixth_Point_Header">Pairwise differential expression with counts in R using DESeq2</h2>
To identify differentially expressed genes, we will transfer the count files generated by HTSeq onto our local machine.  We will the DESeq package within Bioconductor in R to process to provide normalization and statistical analysis of differences among our two sample groups. This R code can be run with the following command:

  Rscript diff_expression_r_script

# Marine DESeq Tutorial
# Load DESeq2 library
# Download needed packages
suppressPackageStartupMessages(library("DESeq2"))
suppressPackageStartupMessages(library("Cairo"))
# Remove globally unexpressed genes

LB2A_SRR1964642 <- as.data.frame(read.table("LB2A_SRR1964642.counts",sep="\t",header=FALSE))
LB2A_SRR1964643 <- as.data.frame(read.table("LB2A_SRR1964643.counts",sep="\t",header=FALSE))
LC2A_SRR1964644 <- as.data.frame(read.table("LC2A_SRR1964644.counts",sep="\t",header=FALSE))
LC2A_SRR1964645 <- as.data.frame(read.table("LC2A_SRR1964645.counts",sep="\t",header=FALSE))

dim(LB2A_SRR1964642)
dim(LB2A_SRR1964643)
dim(LC2A_SRR1964644)
dim(LC2A_SRR1964644)

for (x in 1:27244) {if (LB2A_SRR1964642[x,2] == 0 & LB2A_SRR1964643[x,2] == 0 & LC2A_SRR1964644[x,2] == 0 & LC2A_SRR1964645[x,2] == 0){
LB2A_SRR1964642[x,2] = NA
LB2A_SRR1964643[x,2] = NA
LC2A_SRR1964644[x,2] = NA
LC2A_SRR1964645[x,2] = NA}}

LB2A_SRR1964642 = as.list(LB2A_SRR1964642[complete.cases(LB2A_SRR1964642),])
LB2A_SRR1964643 = as.list(LB2A_SRR1964643[complete.cases(LB2A_SRR1964643),])
LC2A_SRR1964644 = as.list(LC2A_SRR1964644[complete.cases(LC2A_SRR1964644),])
LC2A_SRR1964645 = as.list(LC2A_SRR1964645[complete.cases(LC2A_SRR1964645),])

write.table(LB2A_SRR1964642, file = "LB2A_SRR1964642.counts",sep="\t",col.names=FALSE,row.names=FALSE)
write.table(LB2A_SRR1964643, file = "LB2A_SRR1964643.counts",sep="\t",col.names=FALSE,row.names=FALSE)
write.table(LC2A_SRR1964644, file = "LC2A_SRR1964644.counts",sep="\t",col.names=FALSE,row.names=FALSE)
write.table(LC2A_SRR1964645, file = "LC2A_SRR1964645.counts",sep ="\t",col.names=FALSE,row.names=FALSE)

# Set the working directory
# Directory must have the counts files, for me this is:
directory <- "~/RNA-Seq_genome_assembly_and_annotation"
setwd(directory)
list.files(directory)

# Set the prefix for each output file name
outputPrefix <- "Croaker_DESeq2"

sampleFiles<- c("LB2A_SRR1964642.counts","LB2A_SRR1964643.counts",
                "LC2A_SRR1964644.counts", "LC2A_SRR1964645.counts")

# Liver mRNA profiles of 
# control group (LB2A), * 
# thermal stress group (LC2A), *
sampleNames <- c("LB2A_1","LB2A_2","LC2A_1","LC2A_2")
sampleCondition <- c("control","control","treated","treated")

sampleTable <- data.frame(sampleName = sampleNames,
                          fileName = sampleFiles,
                          condition = sampleCondition)

ddsHTSeq <- DESeqDataSetFromHTSeqCount(sampleTable = sampleTable, directory = directory,
                                       design = ~ condition)

#By default, R will choose a reference level for factors based on alphabetical order. 
# To chose the reference we can use: factor()
treatments <- c("control","treated")
ddsHTSeq$condition
#Setting the factor levels
colData(ddsHTSeq)$condition <- factor(colData(ddsHTSeq)$condition,
                                      levels = treatments)
ddsHTSeq$condition

# Differential expression analysis
#differential expression analysis steps are wrapped into a single function, DESeq()
dds <- DESeq(ddsHTSeq)
# results table will be generated using results() which will include:
#  log2 fold changes, p values and adjusted p values
res <- results(dds)
res
summary(res)
# filter results by p value
res= subset(res, pvalue<0.05)

# order results by pvalue value (most significant to least)
res <- res[order(res$pvalue),]
# should see DataFrame of baseMean, log2Foldchange, stat, pval, padjust

# save data results and normalized reads to csv
resdata <- merge(as.data.frame(res), 
                 as.data.frame(counts(dds,normalized =TRUE)), 
                 by = 'row.names', sort = FALSE)
names(resdata)[1] <- 'gene'

write.csv(resdata, file = paste0(outputPrefix, "-results-with-normalized.csv"))

# send normalized counts to tab delimited file for GSEA, etc.
write.table(as.data.frame(counts(dds),normalized=T), 
            file = paste0(outputPrefix, "_normalized_counts.txt"), sep = '\t')

# produce DataFrame of results of statistical tests
mcols(res, use.names = T)
write.csv(as.data.frame(mcols(res, use.name = T)),
          file = paste0(outputPrefix, "-test-conditions.csv"))

# replacing outlier value with estimated value as predicted by distrubution using
# "trimmed mean" approach. recommended if you have several replicates per treatment
# DESeq2 will automatically do this if you have 7 or more replicates

ddsClean <- replaceOutliersWithTrimmedMean(dds)
ddsClean <- DESeq(ddsClean)
temp_ddsClean <- ddsClean
tab <- table(initial = results(dds)$pvalue < 0.05,
             cleaned = results(ddsClean)$pvalue < 0.05)
addmargins(tab)
write.csv(as.data.frame(tab),file = paste0(outputPrefix, "-replaceoutliers.csv"))
resClean <- results(ddsClean)
resClean = subset(res, pvalue<0.05)
resClean <- resClean[order(resClean$pvalue),]
write.csv(as.data.frame(resClean),file = paste0(outputPrefix, "-replaceoutliers-results.csv"))

####################################################################################
# Exploratory data analysis of RNAseq data with DESeq2
#
# these next R scripts are for a variety of visualization, QC and other plots to
# get a sense of what the RNAseq data looks like based on DESEq2 analysis
#
# 1) MA plot
# 2) rlog stabilization and variance stabiliazation
# 3) PCA plot
# 4) heatmap of clustering analysis
#
#
####################################################################################

# MA plot of RNAseq data for entire dataset
# http://en.wikipedia.org/wiki/MA_plot
# genes with pvalue < 0.1 are colored Red
x11()
plotMA(dds, ylim=c(-8,8),main = "RNAseq experiment")
dev.copy(png, paste0(outputPrefix, "-MAplot_initial_analysis.png"))
dev.off()

# transform raw counts into normalized values
# DESeq2 has two options:  1) rlog transformed and 2) variance stabilization
# variance stabilization is very good for heatmaps, etc.
rld <- rlogTransformation(dds, blind=T)
vsd <- varianceStabilizingTransformation(dds, blind=T)

# save normalized values
write.table(as.data.frame(assay(rld),file = paste0(outputPrefix, "-rlog-transformed-counts.txt"), sep = '\t'))
write.table(as.data.frame(assay(vsd),file = paste0(outputPrefix, "-vst-transformed-counts.txt"), sep = '\t'))


# clustering analysis
# excerpts from http://dwheelerau.com/2014/02/17/how-to-use-deseq2-to-analyse-rnaseq-data/
library("RColorBrewer")
library("gplots")
sampleDists <- dist(t(assay(rld)))
suppressMessages(library("RColorBrewer"))
sampleDistMatrix <- as.matrix(sampleDists)
rownames(sampleDistMatrix) <- paste(colnames(rld), rld$type, sep="")
colnames(sampleDistMatrix) <- paste(colnames(rld), rld$type, sep="")
colors <- colorRampPalette( rev(brewer.pal(8, "Blues")) )(255)
heatmap(sampleDistMatrix,col=colors,margin = c(8,8))
x11()
dev.copy(png,paste0(outputPrefix, "-clustering.png"))
dev.off()

#Principal components plot shows additional but rough clustering of samples
library("genefilter")
library("ggplot2")
library("grDevices")

rv <- rowVars(assay(rld))
select <- order(rv, decreasing=T)[seq_len(min(500,length(rv)))]
pc <- prcomp(assay(vsd)[select,])

# set condition
condition <- treatments
scores <- data.frame(pc$x, condition)

pcaplot <- ggplot(as.data.frame(pc$rotation), aes(PC1, PC2,label=rownames(pc$rotation))) + geom_point(size =5, aes(colour=rownames(pc$rotation))) + ggtitle("Principal Components") + scale_colour_brewer(name = " ", palette = "Set1") + theme(
    plot.title = element_text(face = 'bold'),
    legend.key = element_rect(fill = 'NA'),
    legend.text = element_text(size = 10, face = "bold"),
    axis.text.y = element_text(colour = "Black"),
    axis.text.x = element_text(colour = "Black"),
    axis.title.x = element_text(face = "bold"),
    axis.title.y = element_text(face = 'bold'),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.background = element_rect(color = 'black',fill = NA))
x11()
dev.copy(png,paste0(outputPrefix, "-PCA.png"))
ggsave(pcaplot,file=paste0(outputPrefix, "-ggplot2.png"))


# heatmap of data
library("RColorBrewer")
library("gplots")
# 1000 top expressed genes with heatmap.2
select <- order(rowMeans(counts(ddsClean,normalized=T)),decreasing=T)[1:100]
my_palette <- colorRampPalette(c("blue",'white','red'))(n=100)
heatmap.2(assay(vsd)[select,], col=my_palette,
          scale="row", key=T, keysize=1, symkey=T,
          density.info="none", trace="none",
          cexCol=0.6, labRow=F,
          main="Heatmap of 100 DE Genes in Liver Tissue Comparison")
x11()
dev.copy(png, paste0(outputPrefix, "-HEATMAP.png"))
dev.off()

pc$rotation[,1]
pc$rotation[,2]

resulting files are located in the directory.

Anders, Simon, Paul Theodor Pyl, and Wolfgang Huber. “HTSeq—a Python Framework to Work with High-Throughput Sequencing Data.” Bioinformatics 31.2 (2015): 166–169. PMC. Web. 8 Mar. 2018.

E. Neuwirth, RColorBrewer https://cran.r-project.org/web/packages/RColorBrewer/index.html

Gentleman R, Carey V, Huber W and Hahne F (2017). genefilter: genefilter: methods for filtering genes from high-throughput experiments. R package version 1.60.0. 

Gregory R. Warnes, Ben Bolker, Lodewijk Bonebakker, Robert Gentleman, Wolfgang Huber Andy Liaw, Thomas Lumley, Martin Maechler, Arni Magnusson, Steffen Moeller, Marc Schwartz, Bill Venables, gplots https://cran.r-project.org/web/packages/gplots/index.html

H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009. 

Joshi NA, Fass JN. (2011). Sickle: A sliding-window, adaptive, quality-based trimming tool for FastQ files 
(Version 1.33) [Software].  Available at https://github.com/najoshi/sickle.

Leinonen, Rasko, Hideaki Sugawara, and Martin on behalf of the International Nucleotide Sequence Database Collaboration. “The Sequence Read Archive.” Nucleic Acids Research 39.Database issue (2011): D19–D21. PMC. Web. 8 Mar. 2018.

Li H, Handsaker B, Wysoker A, Fennell T, Ruan J, Homer N, Marth G, Abecasis G, Durbin R, and 1000 Genome Project Data Processing Subgroup, The Sequence alignment/map (SAM) format and SAMtools, Bioinformatics (2009) 25(16) 2078-9

Love MI, Huber W and Anders S (2014). “Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2.” Genome Biology, 15, pp. 550. doi: 10.1186/s13059-014-0550-8. 


